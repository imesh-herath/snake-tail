# -*- coding: utf-8 -*-
"""Model_train_and_inference.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R4Jow9AtsZ0j2bfvMwwoPgkBACAdX53D

### Model training
"""


import json
import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
from torch.utils.data import Dataset,DataLoader
from torchvision.utils import make_grid as vutils
from torchvision import transforms
from torch.optim import lr_scheduler
import random
import os
# import cv2
import torch.optim as optim
from tqdm import tqdm
import time
import copy
from PIL import Image
# import joblib

# def convert_to_dict(obj):
#     obj_dict = {}
#     obj_dict.update(obj.__dict__)
#     return obj_dict

# class CustomEncoder(json.JSONEncoder):
#     def default(self, obj):
#         if isinstance(obj, np.integer):
#             return int(obj)
#         elif isinstance(obj, np.floating):
#             return float(obj)
#         elif isinstance(obj, np.ndarray):
#             return obj.tolist()
#         else:
#             return convert_to_dict(obj)
        
class ModelError:
    def __init__(self, error_code, error_msg):
        self.error_code = error_code
        self.error_msg = error_msg

class Resp:
    def __init__(self, resp):
        self.resp = resp

map_final_dict = {
    0: 'Ahaetulla nasuta',
    1: 'Ahaetulla prasina',
    2: 'Bitis arietans',
    3: 'Bitis gabonica',
    4: 'Boiga irregularis',
    5: 'Boiga kraepelini',
    6: 'Bungarus multicinctus',
    7: 'Chrysopelea ornata',
    8: 'Daboia russelii',
    9: 'Dendrelaphis pictus',
    10: 'Elaphe dione',
    11: 'Eunectes murinus',
    12: 'Gonyosoma oxycephalum',
    13: 'Hypsiglena torquata',
    14: 'Laticauda colubrina',
    15: 'Lycodon capucinus',
    16: 'Morelia spilota',
    17: 'Morelia viridis',
    18: 'Naja atra',
    19: 'Naja naja',
    20: 'Ophiophagus hannah',
    21: 'Protobothrops mucrosquamatus',
    22: 'Psammodynastes pulverulentus',
    23: 'Python molurus',
    24: 'Rhabdophis subminiatus',
    25: 'Rhabdophis tigrinus',
    26: 'Trimeresurus stejnegeri',
    27: 'Tropidolaemus subannulatus',
    28: 'Tropidolaemus wagleri',
    29: 'Xenochrophis piscator'
}

nclass = 30
model2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_widese_b4', pretrained=True)
model2.classifier.fc = nn.Linear(model2.classifier.fc.in_features, nclass)

## Specify device as cpu for inference task
PATH = "./model/state_dict_model_v4.pt"
model2.load_state_dict(torch.load(PATH, map_location=torch.device('cpu')))
model2.eval()

def get_model_for_eval():
  """Gets the broadcasted model."""
  nclass = 30
  model2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_widese_b4', pretrained=True)
  model2.classifier.fc = nn.Linear(model2.classifier.fc.in_features, nclass)

  # PATH = "/content/drive/MyDrive/data-science/state_dict_model_v3.pt"
  ## use latest version
  PATH = "./model/state_dict_model_v4.pt"
  model2.load_state_dict(torch.load(PATH, map_location=torch.device('cpu')))
  model2.eval()

  return model2

from torchvision.datasets.folder import default_loader
class ImageDataset(Dataset):
  def __init__(self, paths, transform=None):
    self.paths = paths
    self.transform = transform
  def __len__(self):
    return len(self.paths)
  def __getitem__(self, index):
    image = default_loader(self.paths[index])
    if self.transform is not None:
      image = self.transform(image)
    return image

import numpy as np
import pandas as pd
# my_array = np.array([10, 5, 8, 20, 15])
# max_index = np.argmax(my_array)
utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')
model = get_model_for_eval()
device = torch.device("cpu")
model.to(device)

def predict_batch_udf(paths: list) -> pd.Series:

  transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(256),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.4718, 0.4429, 0.3738],
                       std=[0.2519, 0.2388, 0.2393])
    ]) ## align transforms with params used in pre-processing step
  images = ImageDataset(paths, transform=transform)
  loader = torch.utils.data.DataLoader(images, batch_size=500, num_workers=8)

  all_predictions = []
  with torch.no_grad():
    for batch in loader:
      output = torch.nn.functional.softmax(model(batch), dim=1)
      predictions = list(model(batch.to(device)).cpu().numpy())
      max_index = np.argmax(np.abs(predictions[0]))
      # print(max_index)
  # results = utils.pick_n_best(predictions=output, n=5)
  # print(output)
  ### return class with highest probability
  max_index = np.argmax(np.abs(output.numpy()))
  snake_cat = map_final_dict[max_index]
  # max_index
  return max_index,snake_cat

while True: 
  # listening standard in
  inputDataStream = sys.stdin.readline()
  message = inputDataStream.replace("\"", "").strip()

  ### get prediction for sample
  pred,snake_cat = predict_batch_udf([message])
  # pred

  # snake_cat

  # final_snakeResp = Resp(snake_cat)

  # sys.stdout.write(snake_cat)

  try:
      json_ser_eta = json.dumps(snake_cat)
      sys.stdout.write(json_ser_eta + "\n")
      sys.stdout.flush()
  except Exception as ex:
      error_msg = json.dumps({"error_code": "007", "error_msg": str(ex)})
      sys.stdout.write(error_msg + "\n")
      sys.stdout.flush()

